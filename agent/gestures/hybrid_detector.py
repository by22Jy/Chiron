"""
æ··åˆæ‰‹åŠ¿æ£€æµ‹å™¨ - æ”¯æŒé™æ€å’ŒåŠ¨æ€æ‰‹åŠ¿
è§£å†³æ‰©å±•æ€§å’ŒåŠ¨æ€æ‰‹åŠ¿é—®é¢˜
"""

import cv2
import mediapipe as mp
import numpy as np
import logging
import math
import time
from collections import deque
from typing import List, Optional, Tuple, Dict, Any
from dataclasses import dataclass

# å¯¼å…¥ç°æœ‰çš„é™æ€æ£€æµ‹å™¨
from mediapipe_detector import GestureResult, MediaPipeGestureDetector, HandPoint

@dataclass
class TrajectoryPoint:
    position: Tuple[float, float]  # (x, y)
    velocity: Tuple[float, float]  # (vx, vy)
    timestamp: float

class DynamicGestureDetector:
    """åŠ¨æ€æ‰‹åŠ¿æ£€æµ‹å™¨ - åŸºäºè½¨è¿¹åˆ†æ"""

    def __init__(self, history_size=20, min_swipe_distance=0.1):
        self.history_size = history_size
        self.min_swipe_distance = min_swipe_distance
        self.trajectory_history = deque(maxlen=history_size)
        self.last_gesture_time = 0
        self.gesture_cooldown = 0.5  # é¿å…é‡å¤è¯†åˆ«

    def add_position(self, landmarks: List[HandPoint], timestamp: float) -> Optional[str]:
        """æ·»åŠ æ‰‹éƒ¨ä½ç½®ï¼Œæ£€æµ‹åŠ¨æ€æ‰‹åŠ¿"""
        # è®¡ç®—æ‰‹å¿ƒä½ç½®
        palm_center = self._calculate_palm_center(landmarks)

        # è®¡ç®—é€Ÿåº¦ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
        velocity = (0, 0)
        if self.trajectory_history:
            last_point = self.trajectory_history[-1]
            dt = timestamp - last_point.timestamp
            if dt > 0:
                dx = palm_center[0] - last_point.position[0]
                dy = palm_center[1] - last_point.position[1]
                velocity = (dx / dt, dy / dt)

        # æ·»åŠ åˆ°è½¨è¿¹å†å²
        trajectory_point = TrajectoryPoint(palm_center, velocity, timestamp)
        self.trajectory_history.append(trajectory_point)

        # å°è¯•è¯†åˆ«æ‰‹åŠ¿
        return self._recognize_dynamic_gesture(timestamp)

    def _calculate_palm_center(self, landmarks: List[HandPoint]) -> Tuple[float, float]:
        """è®¡ç®—æ‰‹å¿ƒä½ç½®"""
        # ä½¿ç”¨æ‰‹è…•å’Œå¤šä¸ªæ‰‹æŒ‡æ ¹éƒ¨çš„å¹³å‡å€¼
        palm_indices = [0, 1, 5, 9, 13, 17]  # æ‰‹è…• + å„æ‰‹æŒ‡æ ¹éƒ¨
        palm_x = sum(landmarks[i].x for i in palm_indices) / len(palm_indices)
        palm_y = sum(landmarks[i].y for i in palm_indices) / len(palm_indices)
        return (palm_x, palm_y)

    def _recognize_dynamic_gesture(self, timestamp: float) -> Optional[str]:
        """è¯†åˆ«åŠ¨æ€æ‰‹åŠ¿"""
        # æ‰‹åŠ¿å†·å´
        if timestamp - self.last_gesture_time < self.gesture_cooldown:
            return None

        if len(self.trajectory_history) < 10:
            return None

        # åˆ†æè½¨è¿¹
        gesture = self._analyze_trajectory()
        if gesture:
            self.last_gesture_time = timestamp
            # æ¸…ç©ºå†å²ï¼Œå‡†å¤‡ä¸‹ä¸€æ¬¡æ‰‹åŠ¿
            self.trajectory_history.clear()

        return gesture

    def _analyze_trajectory(self) -> Optional[str]:
        """åˆ†æè½¨è¿¹æ¨¡å¼"""
        points = list(self.trajectory_history)

        # è®¡ç®—æ€»ä½ç§»
        start_pos = points[0].position
        end_pos = points[-1].position
        dx = end_pos[0] - start_pos[0]
        dy = end_pos[1] - start_pos[1]
        distance = math.sqrt(dx**2 + dy**2)

        # æ£€æŸ¥æœ€å°è·ç¦»
        if distance < self.min_swipe_distance:
            return None

        # è®¡ç®—å¹³å‡é€Ÿåº¦
        total_velocity = sum(math.sqrt(v[0]**2 + v[1]**2) for v in [p.velocity for p in points])
        avg_speed = total_velocity / len(points)

        # è®¡ç®—ä¸»è¦æ–¹å‘
        if abs(dx) > abs(dy):  # æ°´å¹³ä¸»å¯¼
            if dx > 0:
                return "SWIPE_RIGHT"
            else:
                return "SWIPE_LEFT"
        else:  # å‚ç›´ä¸»å¯¼
            if dy > 0:
                return "SWIPE_DOWN"
            else:
                return "SWIPE_UP"

class HybridGestureDetector:
    """æ··åˆæ‰‹åŠ¿æ£€æµ‹å™¨ - ç»“åˆé™æ€å’ŒåŠ¨æ€æ£€æµ‹"""

    def __init__(self,
                 static_min_confidence=0.5,
                 dynamic_min_confidence=0.3,
                 max_hands=2):
        self.static_detector = MediaPipeGestureDetector(
            min_detection_confidence=static_min_confidence,
            min_tracking_confidence=static_min_confidence,
            max_hands=max_hands
        )
        self.dynamic_detector = DynamicGestureDetector()

        # æ¨¡å¼åˆ‡æ¢é˜ˆå€¼
        self.mode = "hybrid"  # "static", "dynamic", "hybrid"
        self.last_static_gesture = None
        self.static_gesture_count = 0

        logging.info('Hybrid gesture detector initialized')

    def detect_hands(self, image: np.ndarray) -> Optional[List[GestureResult]]:
        """æ£€æµ‹æ‰‹éƒ¨å’Œæ‰‹åŠ¿"""
        if image is None:
            return None

        # è½¬æ¢é¢œè‰²ç©ºé—´
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # MediaPipeå¤„ç†
        results = self.static_detector.hands.process(rgb_image)

        if not results.multi_hand_landmarks:
            return None

        gesture_results = []
        current_time = time.time()

        for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
            # è½¬æ¢landmarksæ ¼å¼
            landmarks = [
                (landmark.x, landmark.y, landmark.z if hasattr(landmark, 'z') else 0)
                for landmark in hand_landmarks.landmark
            ]

            # é™æ€æ‰‹åŠ¿æ£€æµ‹
            static_gesture = self._detect_static_gesture(landmarks, current_time)

            # åŠ¨æ€æ‰‹åŠ¿æ£€æµ‹
            dynamic_gesture = self.dynamic_detector.add_position(
                [HandPoint(x, y, z) for x, y, z in landmarks],
                current_time
            )

            # èåˆç»“æœ
            fused_gesture = self._fuse_gesture_results(static_gesture, dynamic_gesture)

            if fused_gesture:
                # åˆ›å»ºè¾¹ç•Œæ¡†ï¼ˆä½¿ç”¨MediaPipeçš„è¾¹ç•Œæ¡†ï¼‰
                if hasattr(results.multi_hand_landmarks[hand_idx], 'bounding_box'):
                    bbox = results.multi_hand_landmarks[hand_idx].bounding_box
                else:
                    # æ‰‹åŠ¨è®¡ç®—è¾¹ç•Œæ¡†
                    xs = [landmark.x for landmark in landmarks]
                    ys = [landmark.y for landmark in landmarks]
                    bbox = (min(xs), min(ys), max(xs), max(ys))

                gesture_results.append(GestureResult(
                    gesture_code=fused_gesture,
                    confidence=0.85,  # æ··åˆæ‰‹åŠ¿çš„ç½®ä¿¡åº¦
                    landmarks=landmarks,
                    timestamp=current_time,
                    bbox=bbox
                ))

        return gesture_results if gesture_results else None

    def _detect_static_gesture(self, landmarks: List[Tuple[float, float, float]], timestamp: float) -> Optional[str]:
        """æ£€æµ‹é™æ€æ‰‹åŠ¿"""
        finger_states = self.static_detector._get_finger_states(landmarks)

        # é™æ€æ‰‹åŠ¿æ£€æµ‹é€»è¾‘
        if self.static_detector._is_pointing_up(finger_states):
            return 'POINT_UP'
        elif self.static_detector._is_pointing_index(finger_states):
            return 'POINT_INDEX'
        elif self.static_detector._is_thumbs_up(finger_states):
            return 'THUMBS_UP'
        elif self.static_detector._is_thumbs_down(finger_states):
            return 'THUMBS_DOWN'
        elif self.static_detector._is_open_palm(finger_states):
            return 'OPEN_PALM'
        elif self.static_detector._is_closed_fist(finger_states):
            return 'CLOSED_FIST'
        elif self.static_detector._is_victory(finger_states):
            return 'VICTORY'
        elif self.static_detector._is_ok_sign(landmarks):
            return 'OK_SIGN'

        return None

    def _fuse_gesture_results(self, static_gesture: Optional[str], dynamic_gesture: Optional[str]) -> Optional[str]:
        """èåˆé™æ€å’ŒåŠ¨æ€æ‰‹åŠ¿ç»“æœ"""
        # æ ¹æ®æ¨¡å¼å†³å®šèåˆç­–ç•¥
        if self.mode == "static":
            return static_gesture
        elif self.mode == "dynamic":
            return dynamic_gesture
        else:  # hybridæ¨¡å¼
            # ä¼˜å…ˆåŠ¨æ€æ‰‹åŠ¿ï¼ˆé€šå¸¸æ›´æœ‰æ„ä¹‰ï¼‰
            if dynamic_gesture:
                # æ£€æŸ¥æ˜¯å¦ä¸é™æ€æ‰‹åŠ¿å†²çª
                if self._is_gesture_compatible(dynamic_gesture, static_gesture):
                    return dynamic_gesture
            # å¦åˆ™è¿”å›é™æ€æ‰‹åŠ¿
            return static_gesture

    def _is_gesture_compatible(self, dynamic_gesture: str, static_gesture: Optional[str]) -> bool:
        """æ£€æŸ¥åŠ¨æ€å’Œé™æ€æ‰‹åŠ¿æ˜¯å¦å…¼å®¹"""
        if not static_gesture:
            return True

        # å®šä¹‰å†²çªçš„è§„åˆ™
        incompatible_pairs = {
            ('SWIPE_LEFT', 'THUMBS_UP'),
            ('SWIPE_RIGHT', 'THUMBS_UP'),
            ('SWIPE_DOWN', 'OPEN_PALM'),
            ('SWIPE_UP', 'CLOSED_FIST')
        }

        return (dynamic_gesture, static_gesture) not in incompatible_pairs

    def set_mode(self, mode: str):
        """è®¾ç½®æ£€æµ‹æ¨¡å¼"""
        if mode in ["static", "dynamic", "hybrid"]:
            self.mode = mode
            logging.info(f'Gesture detection mode set to: {mode}')
        else:
            logging.warning(f'Invalid gesture detection mode: {mode}')

# ä¸ºäº†å…¼å®¹æ€§ï¼Œé‡æ–°å®šä¹‰GestureResult
@dataclass
class GestureResult:
    gesture_code: str
    confidence: float
    landmarks: List[Tuple[float, float, float]]
    timestamp: float
    bbox: Optional[Tuple[int, int, int, int]] = None

# ä¸ºäº†å…¼å®¹æ€§ï¼Œå®šä¹‰HandPoint
@dataclass
class HandPoint:
    x: float
    y: float
    z: float = 0.0

def test_hybrid_detector():
    """æµ‹è¯•æ··åˆæ‰‹åŠ¿æ£€æµ‹å™¨"""
    print("ğŸ¯ æ··åˆæ‰‹åŠ¿æ£€æµ‹å™¨æµ‹è¯•")
    print("=" * 40)

    detector = HybridGestureDetector()

    # æ¨¡æ‹Ÿä¸€äº›æ‰‹åŠ¿åºåˆ—
    test_landmarks = []

    # ç”Ÿæˆ21ä¸ªå…³é”®ç‚¹çš„æ¨¡æ‹Ÿæ•°æ®
    for i in range(21):
        # ç®€å•çš„æ‰‹éƒ¨æ¨¡å‹
        x = 0.5 + (i % 5) * 0.02
        y = 0.3 + (i // 5) * 0.1
        z = 0.0
        test_landmarks.append(HandPoint(x, y, z))

    print("æµ‹è¯•é™æ€æ‰‹åŠ¿è¯†åˆ«...")
    static_result = detector._detect_static_gesture([(p.x, p.y, p.z) for p in test_landmarks], time.time())
    print(f"é™æ€æ£€æµ‹ç»“æœ: {static_result}")

    print("\næµ‹è¯•åŠ¨æ€æ‰‹åŠ¿æ£€æµ‹...")
    # æ¨¡æ‹Ÿè½¨è¿¹
    detector.dynamic_detector.trajectory_history.clear()

    # æ¨¡æ‹Ÿå·¦æ»‘è½¨è¿¹
    for i in range(15):
        x = 0.8 - i * 0.02  # ä»å³å‘å·¦
        y = 0.5 + math.sin(i * 0.5) * 0.05
        timestamp = time.time() + i * 0.03

        # æ›´æ–°æµ‹è¯•æ•°æ®
        for j, point in enumerate(test_landmarks):
            point.x = x + (j % 5 - 2) * 0.01
            point.y = y + (j // 5 - 1) * 0.01

        landmarks = [(p.x, p.y, p.z) for p in test_landmarks]
        dynamic_result = detector.dynamic_detector.add_position(
            [HandPoint(x, y, z) for x, y, z in landmarks],
            timestamp
        )

        if dynamic_result:
            print(f"åŠ¨æ€æ£€æµ‹ç»“æœ: {dynamic_result}")

    print("\næµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_hybrid_detector()